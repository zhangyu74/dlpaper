# Generative Pretraining from Pixels (ViT第一篇论文)
### Blog:
 **OpenAI**: [Image GPT](https://openai.com/index/image-gpt/)。
### 视频:
 **Yannic Kilcher**: [Image GPT: Generative Pretraining from Pixels (Paper Explained)](https://www.youtube.com/watch?v=TrdevFK_am4&list=LL&index=8)。
### 代码:
 **Vit_Model_prototye_Dataset_MNIST**  
 **Vit_Model_prototye_Dataset_oxford-iiit-pet**

# AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE（大规模图像识别的Transformer）
### 视频:
 **Yannic Kilcher**: [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (Paper Explained)](https://www.youtube.com/watch?v=TrdevFK_am4&list=LL&index=8)。
### 代码:
 **Vit_Model_vit-base-patch16-224-in21k_Dataset_Cifar10**
> **James Briggs**:[Vision Transformers (ViT) Explained + Fine-tuning in Python](https://www.youtube.com/watch?v=qU7wO02urYU&list=LL&index=11&t=78s)。  
> **pinecone-io**:[Vision Transformers (ViT) Walkthrough ](https://github.com/pinecone-io/examples/blob/master/learn/search/image/image-retrieval-ebook/vision-transformers/vit.ipynb)  
> **提示：** cifar 数据1.5G。训练时间很长，约2个小时，12500/12500 : < :, Epoch 4/4。

# Swin Transformer: Hierarchical Vision Transformer using Shifted Windows （窗口Transformer）
### 代码:
 **Vit_Model_swinv2_base_window8_256_Dataset_oxford-iiit-pet**
 **Vit_Model_swinv2_base_window8_256_Dataset_oxford-iiit-pet_onlyTest**


